 INFO [2020-10-01 09:05:22,956] ({main} RemoteInterpreterServer.java[main]:261) - URL:jar:file:/zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar!/org/apache/zeppelin/interpreter/remote/RemoteInterpreterServer.class
 INFO [2020-10-01 09:05:23,036] ({main} RemoteInterpreterServer.java[<init>]:162) - Launching ThriftServer at 172.17.0.2:43153
 INFO [2020-10-01 09:05:23,053] ({main} RemoteInterpreterServer.java[<init>]:166) - Starting remote interpreter server on port 43153
 INFO [2020-10-01 09:05:23,054] ({Thread-0} RemoteInterpreterServer.java[run]:203) - Starting remote interpreter server on port 43153
 INFO [2020-10-01 09:05:23,066] ({Thread-1} RemoteInterpreterUtils.java[registerInterpreter]:165) - callbackHost: 172.17.0.2, callbackPort: 46327, callbackInfo: CallbackInfo(host:172.17.0.2, port:43153)
 INFO [2020-10-01 09:05:23,324] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-10-01 09:05:23,328] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2020-10-01 09:05:23,340] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2020-10-01 09:05:23,359] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2020-10-01 09:05:23,365] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.IPySparkInterpreter
 INFO [2020-10-01 09:05:23,368] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkRInterpreter
 WARN [2020-10-01 09:05:23,482] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2020-10-01 09:05:23,530] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2020-10-01 09:05:23,530] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:131) - Server Port: 8080
 INFO [2020-10-01 09:05:23,530] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-10-01 09:05:23,542] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.1
 INFO [2020-10-01 09:05:23,547] ({pool-1-thread-1} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 INFO [2020-10-01 09:05:23,569] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:114) - Job 20201001-090504_2039710210 started by scheduler interpreter_1188586985
 INFO [2020-10-01 09:05:23,636] ({pool-2-thread-4} NewSparkInterpreter.java[open]:83) - Using Scala Version: 2.11
 INFO [2020-10-01 09:05:31,402] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Running Spark version 2.2.1
 WARN [2020-10-01 09:05:31,843] ({pool-2-thread-4} NativeCodeLoader.java[<clinit>]:62) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO [2020-10-01 09:05:32,419] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Submitted application: Zeppelin
 INFO [2020-10-01 09:05:32,451] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Changing view acls to: root
 INFO [2020-10-01 09:05:32,452] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Changing modify acls to: root
 INFO [2020-10-01 09:05:32,454] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Changing view acls groups to: 
 INFO [2020-10-01 09:05:32,454] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Changing modify acls groups to: 
 INFO [2020-10-01 09:05:32,455] ({pool-2-thread-4} Logging.scala[logInfo]:54) - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
 INFO [2020-10-01 09:05:33,003] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Successfully started service 'sparkDriver' on port 36403.
 INFO [2020-10-01 09:05:33,051] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registering MapOutputTracker
 INFO [2020-10-01 09:05:33,102] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registering BlockManagerMaster
 INFO [2020-10-01 09:05:33,107] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO [2020-10-01 09:05:33,108] ({pool-2-thread-4} Logging.scala[logInfo]:54) - BlockManagerMasterEndpoint up
 INFO [2020-10-01 09:05:33,125] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Created local directory at /tmp/blockmgr-66706335-6764-464b-8e53-ceb5f5730e60
 INFO [2020-10-01 09:05:33,206] ({pool-2-thread-4} Logging.scala[logInfo]:54) - MemoryStore started with capacity 408.9 MB
 INFO [2020-10-01 09:05:33,492] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registering OutputCommitCoordinator
 INFO [2020-10-01 09:05:33,668] ({pool-2-thread-4} Log.java[initialized]:192) - Logging initialized @11060ms
 INFO [2020-10-01 09:05:33,773] ({pool-2-thread-4} Server.java[doStart]:345) - jetty-9.3.z-SNAPSHOT
 INFO [2020-10-01 09:05:33,801] ({pool-2-thread-4} Server.java[doStart]:403) - Started @11192ms
 INFO [2020-10-01 09:05:33,834] ({pool-2-thread-4} AbstractConnector.java[doStart]:270) - Started ServerConnector@2de29b5b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
 INFO [2020-10-01 09:05:33,834] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Successfully started service 'SparkUI' on port 4040.
 INFO [2020-10-01 09:05:33,874] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6472e622{/jobs,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,876] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@41f9e607{/jobs/json,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,879] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@70381062{/jobs/job,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,884] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5174dc9d{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,886] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6ba18c7f{/stages,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,888] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@20963568{/stages/json,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,889] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5db87416{/stages/stage,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,893] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5d82289c{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,895] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2e1ba1d6{/stages/pool,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,898] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6104a20{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,900] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5bf51dd1{/storage,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,901] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@47db0374{/storage/json,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,903] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4705480{/storage/rdd,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,905] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2801d4b7{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,908] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@1fdb9719{/environment,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,911] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@7b49fc72{/environment/json,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,912] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@69969003{/executors,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,916] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@593fdab4{/executors/json,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,918] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@1b959871{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,920] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@59144c79{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,934] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@586c35ec{/static,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,935] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6f290062{/,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,938] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4a667489{/api,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,941] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@73bba47{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,942] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@21e3374a{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:33,947] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Bound SparkUI to 0.0.0.0, and started at http://172.17.0.2:4040
 INFO [2020-10-01 09:05:34,007] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Added JAR /zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar at spark://172.17.0.2:36403/jars/spark-interpreter-0.8.1.jar with timestamp 1601543134007
 INFO [2020-10-01 09:05:34,145] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Starting executor ID driver on host localhost
 INFO [2020-10-01 09:05:34,157] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Using REPL class URI: spark://172.17.0.2:36403/classes
 INFO [2020-10-01 09:05:34,200] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35125.
 INFO [2020-10-01 09:05:34,201] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Server created on 172.17.0.2:35125
 INFO [2020-10-01 09:05:34,202] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO [2020-10-01 09:05:34,204] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registering BlockManager BlockManagerId(driver, 172.17.0.2, 35125, None)
 INFO [2020-10-01 09:05:34,209] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Registering block manager 172.17.0.2:35125 with 408.9 MB RAM, BlockManagerId(driver, 172.17.0.2, 35125, None)
 INFO [2020-10-01 09:05:34,219] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registered BlockManager BlockManagerId(driver, 172.17.0.2, 35125, None)
 INFO [2020-10-01 09:05:34,219] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Initialized BlockManager: BlockManagerId(driver, 172.17.0.2, 35125, None)
 INFO [2020-10-01 09:05:34,453] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@7dd37e0f{/metrics/json,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:41,283] ({pool-2-thread-4} SparkShims.java[loadShims]:62) - Initializing shims for Spark 2.x
 INFO [2020-10-01 09:05:42,079] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/zeppelin/spark-warehouse').
 INFO [2020-10-01 09:05:42,080] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Warehouse path is 'file:/zeppelin/spark-warehouse'.
 INFO [2020-10-01 09:05:42,093] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@558bbd14{/SQL,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:42,094] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@20dd7502{/SQL/json,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:42,095] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@283d44f5{/SQL/execution,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:42,097] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@68abffb6{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:42,099] ({pool-2-thread-4} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4e083478{/static/sql,null,AVAILABLE,@Spark}
 INFO [2020-10-01 09:05:43,397] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registered StateStoreCoordinator endpoint
 INFO [2020-10-01 09:05:44,715] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Pruning directories with: 
 INFO [2020-10-01 09:05:44,719] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Post-Scan Filters: (length(trim(value#0)) > 0)
 INFO [2020-10-01 09:05:44,721] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Output Data Schema: struct<value: string>
 INFO [2020-10-01 09:05:44,734] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Pushed Filters: 
 INFO [2020-10-01 09:05:45,054] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Code generated in 187.493 ms
 INFO [2020-10-01 09:05:45,366] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Code generated in 29.149 ms
 INFO [2020-10-01 09:05:45,465] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Block broadcast_0 stored as values in memory (estimated size 288.4 KB, free 408.6 MB)
 INFO [2020-10-01 09:05:45,545] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.2 KB, free 408.6 MB)
 INFO [2020-10-01 09:05:45,548] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_0_piece0 in memory on 172.17.0.2:35125 (size: 24.2 KB, free: 408.9 MB)
 INFO [2020-10-01 09:05:45,552] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Created broadcast 0 from csv at <console>:29
 INFO [2020-10-01 09:05:45,566] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Planning scan with bin packing, max size: 39479118 bytes, open cost is considered as scanning 4194304 bytes.
 INFO [2020-10-01 09:05:45,690] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Starting job: csv at <console>:29
 INFO [2020-10-01 09:05:45,704] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 0 (csv at <console>:29) with 1 output partitions
 INFO [2020-10-01 09:05:45,705] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 0 (csv at <console>:29)
 INFO [2020-10-01 09:05:45,706] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-10-01 09:05:45,709] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-10-01 09:05:45,727] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at <console>:29), which has no missing parents
 INFO [2020-10-01 09:05:45,864] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_1 stored as values in memory (estimated size 8.2 KB, free 408.6 MB)
 INFO [2020-10-01 09:05:45,868] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.3 KB, free 408.6 MB)
 INFO [2020-10-01 09:05:45,869] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Added broadcast_1_piece0 in memory on 172.17.0.2:35125 (size: 4.3 KB, free: 408.9 MB)
 INFO [2020-10-01 09:05:45,871] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
 INFO [2020-10-01 09:05:45,891] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at <console>:29) (first 15 tasks are for partitions Vector(0))
 INFO [2020-10-01 09:05:45,893] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 0.0 with 1 tasks
 INFO [2020-10-01 09:05:45,959] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5269 bytes)
 INFO [2020-10-01 09:05:45,976] ({Executor task launch worker for task 0} Logging.scala[logInfo]:54) - Running task 0.0 in stage 0.0 (TID 0)
 INFO [2020-10-01 09:05:45,982] ({Executor task launch worker for task 0} Logging.scala[logInfo]:54) - Fetching spark://172.17.0.2:36403/jars/spark-interpreter-0.8.1.jar with timestamp 1601543134007
 INFO [2020-10-01 09:05:46,109] ({Executor task launch worker for task 0} TransportClientFactory.java[createClient]:254) - Successfully created connection to /172.17.0.2:36403 after 47 ms (0 ms spent in bootstraps)
 INFO [2020-10-01 09:05:46,135] ({Executor task launch worker for task 0} Logging.scala[logInfo]:54) - Fetching spark://172.17.0.2:36403/jars/spark-interpreter-0.8.1.jar to /tmp/spark-c0d42813-7593-40bd-be58-8fd1501526ab/userFiles-57f751dc-9b4a-43e2-8194-3a1cfd254fc8/fetchFileTemp4594250459100638917.tmp
 INFO [2020-10-01 09:05:46,334] ({Executor task launch worker for task 0} Logging.scala[logInfo]:54) - Adding file:/tmp/spark-c0d42813-7593-40bd-be58-8fd1501526ab/userFiles-57f751dc-9b4a-43e2-8194-3a1cfd254fc8/spark-interpreter-0.8.1.jar to class loader
 INFO [2020-10-01 09:05:46,435] ({Executor task launch worker for task 0} Logging.scala[logInfo]:54) - Reading File path: file:///zeppelin/data/amazon.csv, range: 0-35284814, partition values: [empty row]
 INFO [2020-10-01 09:05:46,474] ({Executor task launch worker for task 0} Logging.scala[logInfo]:54) - Code generated in 29.6723 ms
 INFO [2020-10-01 09:05:46,568] ({Executor task launch worker for task 0} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 0.0 (TID 0). 1537 bytes result sent to driver
 INFO [2020-10-01 09:05:46,583] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 0.0 (TID 0) in 653 ms on localhost (executor driver) (1/1)
 INFO [2020-10-01 09:05:46,587] ({task-result-getter-0} Logging.scala[logInfo]:54) - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO [2020-10-01 09:05:46,595] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 0 (csv at <console>:29) finished in 0.679 s
 INFO [2020-10-01 09:05:46,601] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Job 0 finished: csv at <console>:29, took 0.909672 s
 INFO [2020-10-01 09:05:46,659] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Pruning directories with: 
 INFO [2020-10-01 09:05:46,659] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Post-Scan Filters: 
 INFO [2020-10-01 09:05:46,660] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Output Data Schema: struct<value: string>
 INFO [2020-10-01 09:05:46,660] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Pushed Filters: 
 INFO [2020-10-01 09:05:46,683] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Code generated in 19.0635 ms
 INFO [2020-10-01 09:05:46,700] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Block broadcast_2 stored as values in memory (estimated size 288.4 KB, free 408.3 MB)
 INFO [2020-10-01 09:05:46,727] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.2 KB, free 408.3 MB)
 INFO [2020-10-01 09:05:46,728] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Added broadcast_2_piece0 in memory on 172.17.0.2:35125 (size: 24.2 KB, free: 408.8 MB)
 INFO [2020-10-01 09:05:46,730] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Created broadcast 2 from csv at <console>:29
 INFO [2020-10-01 09:05:46,730] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Planning scan with bin packing, max size: 39479118 bytes, open cost is considered as scanning 4194304 bytes.
 INFO [2020-10-01 09:05:46,853] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Starting job: csv at <console>:29
 INFO [2020-10-01 09:05:46,855] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 1 (csv at <console>:29) with 1 output partitions
 INFO [2020-10-01 09:05:46,855] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 1 (csv at <console>:29)
 INFO [2020-10-01 09:05:46,855] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-10-01 09:05:46,856] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-10-01 09:05:46,856] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at <console>:29), which has no missing parents
 INFO [2020-10-01 09:05:46,864] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_3 stored as values in memory (estimated size 13.1 KB, free 408.3 MB)
 INFO [2020-10-01 09:05:46,867] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.0 KB, free 408.3 MB)
 INFO [2020-10-01 09:05:46,868] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_3_piece0 in memory on 172.17.0.2:35125 (size: 7.0 KB, free: 408.8 MB)
 INFO [2020-10-01 09:05:46,869] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
 INFO [2020-10-01 09:05:46,870] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at <console>:29) (first 15 tasks are for partitions Vector(0))
 INFO [2020-10-01 09:05:46,870] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 1.0 with 1 tasks
 INFO [2020-10-01 09:05:46,874] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5269 bytes)
 INFO [2020-10-01 09:05:46,874] ({Executor task launch worker for task 1} Logging.scala[logInfo]:54) - Running task 0.0 in stage 1.0 (TID 1)
 INFO [2020-10-01 09:05:46,895] ({Executor task launch worker for task 1} Logging.scala[logInfo]:54) - Reading File path: file:///zeppelin/data/amazon.csv, range: 0-35284814, partition values: [empty row]
 INFO [2020-10-01 09:05:47,608] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removed broadcast_1_piece0 on 172.17.0.2:35125 in memory (size: 4.3 KB, free: 408.8 MB)
 INFO [2020-10-01 09:05:47,625] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_0_piece0 on 172.17.0.2:35125 in memory (size: 24.2 KB, free: 408.9 MB)
 INFO [2020-10-01 09:05:47,627] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 5
 INFO [2020-10-01 09:05:47,628] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 2
 INFO [2020-10-01 09:05:47,628] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 3
 INFO [2020-10-01 09:05:47,628] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 4
 INFO [2020-10-01 09:05:47,628] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 1
 INFO [2020-10-01 09:05:47,628] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 0
 INFO [2020-10-01 09:05:48,163] ({Executor task launch worker for task 1} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 1.0 (TID 1). 1591 bytes result sent to driver
 INFO [2020-10-01 09:05:48,165] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 1.0 (TID 1) in 1292 ms on localhost (executor driver) (1/1)
 INFO [2020-10-01 09:05:48,166] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 1 (csv at <console>:29) finished in 1.281 s
 INFO [2020-10-01 09:05:48,167] ({task-result-getter-1} Logging.scala[logInfo]:54) - Removed TaskSet 1.0, whose tasks have all completed, from pool 
 INFO [2020-10-01 09:05:48,167] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Job 1 finished: csv at <console>:29, took 1.313532 s
 INFO [2020-10-01 09:05:48,210] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Parsing command: amazon
 INFO [2020-10-01 09:05:48,489] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20201001-090504_2039710210 finished by scheduler interpreter_1188586985
 INFO [2020-10-01 09:05:48,679] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:114) - Job 20201001-090522_688400351 started by scheduler interpreter_1188586985
 INFO [2020-10-01 09:05:48,702] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Parsing command: select * from amazon where product_name like  '%hobby%'
 INFO [2020-10-01 09:05:48,993] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Pruning directories with: 
 INFO [2020-10-01 09:05:48,994] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Post-Scan Filters: isnotnull(product_name#13),Contains(product_name#13, hobby)
 INFO [2020-10-01 09:05:48,994] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Output Data Schema: struct<uniq_id: string, product_name: string, manufacturer: string, price: string, number_available_in_stock: string ... 15 more fields>
 INFO [2020-10-01 09:05:48,997] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Pushed Filters: IsNotNull(product_name),StringContains(product_name,hobby)
 INFO [2020-10-01 09:05:49,129] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Code generated in 86.1085 ms
 INFO [2020-10-01 09:05:49,203] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Code generated in 43.5135 ms
 INFO [2020-10-01 09:05:49,225] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Block broadcast_4 stored as values in memory (estimated size 288.9 KB, free 408.3 MB)
 INFO [2020-10-01 09:05:49,233] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.2 KB, free 408.3 MB)
 INFO [2020-10-01 09:05:49,235] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_4_piece0 in memory on 172.17.0.2:35125 (size: 24.2 KB, free: 408.8 MB)
 INFO [2020-10-01 09:05:49,236] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Created broadcast 4 from take at NativeMethodAccessorImpl.java:0
 INFO [2020-10-01 09:05:49,241] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Planning scan with bin packing, max size: 39479118 bytes, open cost is considered as scanning 4194304 bytes.
 INFO [2020-10-01 09:05:49,253] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Starting job: take at NativeMethodAccessorImpl.java:0
 INFO [2020-10-01 09:05:49,257] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 2 (take at NativeMethodAccessorImpl.java:0) with 1 output partitions
 INFO [2020-10-01 09:05:49,257] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 2 (take at NativeMethodAccessorImpl.java:0)
 INFO [2020-10-01 09:05:49,258] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-10-01 09:05:49,258] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-10-01 09:05:49,259] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 2 (MapPartitionsRDD[10] at take at NativeMethodAccessorImpl.java:0), which has no missing parents
 INFO [2020-10-01 09:05:49,265] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_5 stored as values in memory (estimated size 16.4 KB, free 408.3 MB)
 INFO [2020-10-01 09:05:49,316] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.2 KB, free 408.2 MB)
 INFO [2020-10-01 09:05:49,317] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Added broadcast_5_piece0 in memory on 172.17.0.2:35125 (size: 7.2 KB, free: 408.8 MB)
 INFO [2020-10-01 09:05:49,328] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
 INFO [2020-10-01 09:05:49,329] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at take at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
 INFO [2020-10-01 09:05:49,329] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 2.0 with 1 tasks
 INFO [2020-10-01 09:05:49,330] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5269 bytes)
 INFO [2020-10-01 09:05:49,331] ({Executor task launch worker for task 2} Logging.scala[logInfo]:54) - Running task 0.0 in stage 2.0 (TID 2)
 INFO [2020-10-01 09:05:49,366] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_3_piece0 on 172.17.0.2:35125 in memory (size: 7.0 KB, free: 408.8 MB)
 INFO [2020-10-01 09:05:49,375] ({Executor task launch worker for task 2} Logging.scala[logInfo]:54) - Reading File path: file:///zeppelin/data/amazon.csv, range: 0-35284814, partition values: [empty row]
 INFO [2020-10-01 09:05:49,445] ({Executor task launch worker for task 2} Logging.scala[logInfo]:54) - Code generated in 67.2962 ms
 INFO [2020-10-01 09:05:51,392] ({Executor task launch worker for task 2} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 2.0 (TID 2). 16444 bytes result sent to driver
 INFO [2020-10-01 09:05:51,394] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 2.0 (TID 2) in 2064 ms on localhost (executor driver) (1/1)
 INFO [2020-10-01 09:05:51,395] ({task-result-getter-2} Logging.scala[logInfo]:54) - Removed TaskSet 2.0, whose tasks have all completed, from pool 
 INFO [2020-10-01 09:05:51,395] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 2 (take at NativeMethodAccessorImpl.java:0) finished in 2.051 s
 INFO [2020-10-01 09:05:51,396] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Job 2 finished: take at NativeMethodAccessorImpl.java:0, took 2.139378 s
 INFO [2020-10-01 09:05:51,479] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20201001-090522_688400351 finished by scheduler interpreter_1188586985
 INFO [2020-10-01 09:06:07,805] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:114) - Job 20201001-090548_1674938257 started by scheduler interpreter_1188586985
 INFO [2020-10-01 09:06:08,231] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:120) - Job 20201001-090548_1674938257 finished by scheduler interpreter_1188586985
 INFO [2020-10-01 09:06:22,802] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:114) - Job 20201001-090548_1674938257 started by scheduler interpreter_1188586985
 INFO [2020-10-01 09:06:23,321] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20201001-090548_1674938257 finished by scheduler interpreter_1188586985
 INFO [2020-10-01 09:06:26,223] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:114) - Job 20201001-090607_1032212090 started by scheduler interpreter_1188586985
 INFO [2020-10-01 09:06:26,515] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:120) - Job 20201001-090607_1032212090 finished by scheduler interpreter_1188586985
 INFO [2020-10-01 09:35:35,047] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 85
 INFO [2020-10-01 09:35:35,055] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 54
 INFO [2020-10-01 09:35:35,062] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_5_piece0 on 172.17.0.2:35125 in memory (size: 7.2 KB, free: 408.9 MB)
 INFO [2020-10-01 09:35:35,064] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 58
 INFO [2020-10-01 09:35:35,064] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 57
 INFO [2020-10-01 09:35:35,064] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 84
 INFO [2020-10-01 09:35:35,066] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removed broadcast_4_piece0 on 172.17.0.2:35125 in memory (size: 24.2 KB, free: 408.9 MB)
 INFO [2020-10-01 09:35:35,067] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 55
 INFO [2020-10-01 09:35:35,068] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 83
 INFO [2020-10-01 09:35:35,068] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 56
 INFO [2020-10-01 09:35:35,069] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_2_piece0 on 172.17.0.2:35125 in memory (size: 24.2 KB, free: 408.9 MB)
 INFO [2020-10-01 09:35:35,070] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 87
 INFO [2020-10-01 09:35:35,071] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 86
 INFO [2020-10-01 09:35:35,072] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 88
